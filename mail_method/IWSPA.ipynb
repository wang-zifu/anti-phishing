{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# paths of the input files\n",
    "no_head_train_path_0 = '../data/phishing/IWSPA-AP-traindata/phish/'\n",
    "no_head_train_path_1 = '../data/phishing/IWSPA-AP-traindata/legit/'\n",
    "head_train_path_0 = '../data/phishing/Dataset_Full_Header_Training/Dataset_Submit_Phish/'\n",
    "head_train_path_1 = '../data/phishing/Dataset_Full_Header_Training/Dataset_Submit_Legit/'\n",
    "no_head_test_path = '../data/phishing/IWSPA-APTestData/testdata_noheaders/'\n",
    "head_test_path = '../data/phishing/IWSPA-APTestData/testdata_fullheaders/'\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os, re, string\n",
    "import numpy as np\n",
    "import fasttext\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.encode('utf-8').decode('utf-8')\n",
    "    while '\\n' in text:\n",
    "        text = text.replace('\\n', ' ')\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    words = text.split()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stripped = []\n",
    "    for token in words: \n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            stripped.append(new_token.lower())\n",
    "    text = ' '.join(stripped)\n",
    "    return text\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def get_data(path):\n",
    "    text_list = list()\n",
    "    files = os.listdir(path)\n",
    "    for text_file in files:\n",
    "        file_path = os.path.join(path, text_file)\n",
    "        read_file = open(file_path,'r+')\n",
    "        read_text = read_file.read()\n",
    "        read_file.close()\n",
    "        cleaned_text = clean_text(read_text)\n",
    "        text_list.append(cleaned_text)\n",
    "    return text_list, files\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "no_head_train_0, temp = get_data(no_head_train_path_0)\n",
    "no_head_train_1, temp = get_data(no_head_train_path_1)\n",
    "head_train_0, temp = get_data(head_train_path_0)\n",
    "head_train_1, temp = get_data(head_train_path_1)\n",
    "no_head_test, no_head_files = get_data(no_head_test_path)\n",
    "head_test, head_files = get_data(head_test_path)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "no_head_train = no_head_train_0 + no_head_train_1\n",
    "no_head_labels_train = ([0] * len(no_head_train_0)) + ([1] * len(no_head_train_1))\n",
    "\n",
    "head_train = head_train_0 + head_train_1\n",
    "head_labels_train = ([0] * len(head_train_0)) + ([1] * len(head_train_1))\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer()\n",
    "X = tf_vectorizer.fit_transform(no_head_train)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "#total words 1101893\n",
      "#unique words 82075\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print ('#total words', np.matrix.sum(X.todense()))\n",
    "print ('#unique words',len(set(tf_vectorizer.get_feature_names())))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(head_train)\n",
    "X = tf_vectorizer.fit_transform(head_train)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "#total words 2065327\n",
      "#unique words 117085\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print ('#total words', np.matrix.sum(X.todense()))\n",
    "print ('#unique words',len(set(tf_vectorizer.get_feature_names())))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "shuffled_indices = np.random.permutation(len(no_head_labels_train))\n",
    "train_data = np.array(no_head_train)[shuffled_indices]\n",
    "train_data = train_data.tolist()\n",
    "train_label = np.array(no_head_labels_train)[shuffled_indices]\n",
    "train_label = train_label.tolist()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "temp_train_data = train_data[0:int(0.8*len(train_data))]\n",
    "temp_train_label = train_label[0:int(0.8*len(train_label))]\n",
    "temp_test_data = train_data[int(0.8*len(train_data)):]\n",
    "temp_test_labels = train_label[int(0.8*len(train_label)):]\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fast_train_file = './.data/fast_train.txt'\n",
    "fast_test_file = './.data/fast_test.txt'\n",
    "writeFile = open(fast_train_file, 'w')\n",
    "for text, label in zip(temp_train_data, temp_train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "\n",
    "writeFile = open(fast_test_file, 'w')\n",
    "for text, label in zip(temp_test_data, temp_test_labels):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(fast_train_file, './.models/Amrita-NLP_TOP_fastText_noheaders')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "result = classifier.test(fast_test_file)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9676855895196507, 0.9676855895196507, 1145)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "result.precision, result.recall, result.nexamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1 100 5 1 utf-8 softmax 0 0.0001\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print (classifier.min_count, classifier.dim, classifier.epoch, classifier.word_ngrams, classifier.encoding, classifier.loss_name, classifier.maxn, classifier.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "final_fast_train_file = './.data/final_fast_train.txt'\n",
    "writeFile = open(final_fast_train_file, 'w')\n",
    "for text, label in zip(train_data, train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(final_fast_train_file, './.models/Amrita-NLP_TOP_fastText_noheaders')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4300"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "len(no_head_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range (len(no_head_test)):\n",
    "    if len(no_head_test[i]) == 0:\n",
    "        no_head_test[i] = '  '\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "final_labels = classifier.predict(no_head_test)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "writeFile = open('./.submission/Amrita-NLP_submission_TOP_noheaders_1.txt', 'w')\n",
    "for value, test_file in zip(final_labels,no_head_files):\n",
    "    writeFile.write(test_file + ' ' + value[0])\n",
    "    writeFile.write('\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "shuffled_indices = np.random.permutation(len(head_labels_train))\n",
    "train_data = np.array(head_train)[shuffled_indices]\n",
    "train_data = train_data.tolist()\n",
    "train_label = np.array(head_labels_train)[shuffled_indices]\n",
    "train_label = train_label.tolist()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "temp_train_data = train_data[0:int(0.8*len(train_data))]\n",
    "temp_train_label = train_label[0:int(0.8*len(train_label))]\n",
    "temp_test_data = train_data[int(0.8*len(train_data)):]\n",
    "temp_test_labels = train_label[int(0.8*len(train_label)):]\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fast_train_file = './.data/fast_train.txt'\n",
    "fast_test_file = './.data/fast_test.txt'\n",
    "writeFile = open(fast_train_file, 'w')\n",
    "for text, label in zip(temp_train_data, temp_train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "\n",
    "writeFile = open(fast_test_file, 'w')\n",
    "for text, label in zip(temp_test_data, temp_test_labels):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(fast_train_file, './.models/Amrita-NLP_TOP_fastText_headers')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result = classifier.test(fast_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9923664122137404, 0.9923664122137404, 917)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "result.precision, result.recall, result.nexamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "final_fast_train_file = './.data/final_fast_train.txt'\n",
    "writeFile = open(final_fast_train_file, 'w')\n",
    "for text, label in zip(train_data, train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(final_fast_train_file, './.models/Amrita-NLP_TOP_fastText_headers')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "final_labels = classifier.predict(head_test)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "writeFile = open('./.submission/Amrita-NLP_submission_TOP_headers_1.txt', 'w')\n",
    "for value, test_file in zip(final_labels, head_files):\n",
    "    writeFile.write(test_file + ' ' + value[0])\n",
    "    writeFile.write('\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "no_head_train = no_head_train_0 + no_head_train_1\n",
    "no_head_labels_train = ([0] * len(no_head_train_0)) + ([1] * len(no_head_train_1))\n",
    "\n",
    "head_train = head_train_0 + head_train_1\n",
    "head_labels_train = ([0] * len(head_train_0)) + ([1] * len(head_train_1))\n",
    "\n",
    "temp_train = no_head_train + head_train\n",
    "temp_labels = no_head_labels_train + head_labels_train\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "shuffled_indices = np.random.permutation(len(temp_labels))\n",
    "train_data = np.array(temp_train)[shuffled_indices]\n",
    "train_data = train_data.tolist()\n",
    "train_label = np.array(temp_labels)[shuffled_indices]\n",
    "train_label = train_label.tolist()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "temp_train_data = train_data[0:int(0.8*len(train_data))]\n",
    "temp_train_label = train_label[0:int(0.8*len(train_label))]\n",
    "temp_test_data = train_data[int(0.8*len(train_data)):]\n",
    "temp_test_labels = train_label[int(0.8*len(train_label)):]\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fast_train_file = './.data/fast_train.txt'\n",
    "fast_test_file = './.data/fast_test.txt'\n",
    "writeFile = open(fast_train_file, 'w')\n",
    "for text, label in zip(temp_train_data, temp_train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "\n",
    "writeFile = open(fast_test_file, 'w')\n",
    "for text, label in zip(temp_test_data, temp_test_labels):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(fast_train_file, './.models/model_combined')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result = classifier.test(fast_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.983996120271581, 0.983996120271581, 2062)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 41
    }
   ],
   "source": [
    "result.precision, result.recall, result.nexamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "final_fast_train_file = './.data/final_fast_train.txt'\n",
    "writeFile = open(final_fast_train_file, 'w')\n",
    "for text, label in zip(train_data, train_label):\n",
    "    writeFile.write('__label__'+str(label)+' '+str(text.encode('utf-8'))+'\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = fasttext.supervised(final_fast_train_file, './.models/model_combined')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range (len(no_head_test)):\n",
    "    if len(no_head_test[i]) == 0:\n",
    "        no_head_test[i] = '  '\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_head_labels = classifier.predict(head_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_no_head_labels = classifier.predict(no_head_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "writeFile = open('./.submission/Amrita-NLP_submission_headers_2.txt', 'w')\n",
    "for value, test_file in zip(final_head_labels , head_files):\n",
    "    writeFile.write(test_file + ' ' + value[0])\n",
    "    writeFile.write('\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "writeFile = open('./.submission/Amrita-NLP_submission_noheaders_2.txt', 'w')\n",
    "for value, test_file in zip(final_no_head_labels,no_head_files):\n",
    "    writeFile.write(test_file + ' ' + value[0])\n",
    "    writeFile.write('\\n')\n",
    "writeFile.close()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}