{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "!pip install keras==2.2.4 # critical dependency, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize tensorflow/keras session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "filepath = \"../data/enron/emails.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe called emails\n",
    "emails = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# take a closer look at the first email\n",
    "print(emails.loc[0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron Gov't Affairs provided this report on the Energy and Natural Resources \\nhearing on Natural Gas markets held this morning.  Please note the suggestion \\nthat we provide a list of any specific items that we would like to see added \\nto energy policy legislation:\\n\\nWitnesses from the Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony,\\n\\nI just spoke to the Entergy lawyer, and this merger isn't effective until \\n2/1/01.  She will be sending me documents when they are filed with the \\nDelaware Secretary of State.  So you don't need to worry about this.\\n\\n\\n\\n\\tAnthony Campos\\n\\t01/18/2001 02:52 PM\\n\\t\\t \\n\\t\\t To: Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Start Date: 4/10/01; HourAhead hour: 18;  HourAhead schedule download failed. \\nManual intervention required.\\n\\n    LOG MESSAGES:\\n\\nERROR: File O:\\Portland\\WestDesk\\California Scheduling\\ISO Final \\nSchedules\\2001041018.txt is empty.\\nERROR: File O:\\Portland\\WestDesk\\California Scheduling\\ISO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt; Attached, please find the most recent draft of the ISDA Cross Agreement\\n&gt; Bridge and accompanying memorandum.\\n&gt;\\n&gt; Please do not hesitate to contact John Berry (john.berry@allenovery.com)\\n&gt; or myself with any comments or queries you might have.\\n&gt;\\n&gt; Kimberly Summe\\n&gt;\\n&gt;\\n&gt;\\n&gt;  &lt;&lt;Structural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[IMAGE]  =09  [IMAGE] =20\\n\\n=09\\n=09\\n=09[IMAGE]\\n=09\\n=09\\n=09The 'goal post' motivation factor=20\\n=09=20\\n=09Nov. 9, 2000=20\\n=09=20\\n=09\\n=09[IMAGE]Chip Brown, who covers UT football for The Dallas Morning News,=\\n=20\\nanswers your questions about injuries, Chris Simms, bowl prospects and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  Enron Gov't Affairs provided this report on the Energy and Natural Resources \\nhearing on Natural Gas markets held this morning.  Please note the suggestion \\nthat we provide a list of any specific items that we would like to see added \\nto energy policy legislation:\\n\\nWitnesses from the Energy...\n",
       "1  Anthony,\\n\\nI just spoke to the Entergy lawyer, and this merger isn't effective until \\n2/1/01.  She will be sending me documents when they are filed with the \\nDelaware Secretary of State.  So you don't need to worry about this.\\n\\n\\n\\n\\tAnthony Campos\\n\\t01/18/2001 02:52 PM\\n\\t\\t \\n\\t\\t To: Ta...\n",
       "2  Start Date: 4/10/01; HourAhead hour: 18;  HourAhead schedule download failed. \\nManual intervention required.\\n\\n    LOG MESSAGES:\\n\\nERROR: File O:\\Portland\\WestDesk\\California Scheduling\\ISO Final \\nSchedules\\2001041018.txt is empty.\\nERROR: File O:\\Portland\\WestDesk\\California Scheduling\\ISO ...\n",
       "3  > Attached, please find the most recent draft of the ISDA Cross Agreement\\n> Bridge and accompanying memorandum.\\n>\\n> Please do not hesitate to contact John Berry (john.berry@allenovery.com)\\n> or myself with any comments or queries you might have.\\n>\\n> Kimberly Summe\\n>\\n>\\n>\\n>  <<Structural...\n",
       "4    [IMAGE]  =09  [IMAGE] =20\\n\\n=09\\n=09\\n=09[IMAGE]\\n=09\\n=09\\n=09The 'goal post' motivation factor=20\\n=09=20\\n=09Nov. 9, 2000=20\\n=09=20\\n=09\\n=09[IMAGE]Chip Brown, who covers UT football for The Dallas Morning News,=\\n=20\\nanswers your questions about injuries, Chris Simms, bowl prospects and..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../data/fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Nsamp =1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        tokens = str(row).split(\" \")[:maxtokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lidayuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list(['amina', 'wazi', 'smith', 'streetjohanesburg', 'kznsuth', 'africatel', 'dear', 'sir', 'i', 'pray', 'insha', 'allah', 'mail', 'meet', 'ingood', 'conditioni', 'amina', 'wazi', 'daughter', 'ali', 'hassan', 'iraq', 'i', 'finished', 'studies', 'manchester', 'university', 'england', 'i', 'wish', 'seek', 'assistance', 'claim', 'part', 'father', 'funds', 'usm', 'nine', 'million', 'five', 'hundred', 'thousand', 'dollarsthis', 'happened', 'i', 'foresee', 'danger', 'attack', 'coalition', 'forces', 'united', 'states', 'america', 'i', 'managed', 'move', 'funds', 'united', 'nations', 'country', 'inspection', 'chemical', 'weapons', 'south', 'africaat', 'moment', 'i', 'know', 'problems', 'i', 'wouldnot', 'want', 'funds', 'sit', 'office', 'united', 'nation', 'long', 'demurrage', 'levied', 'agency', 'charge', 'fundsthe', 'funds', 'far', 'watchful', 'eyes', 'kmbeki', 'enterprises', 'affiliated', 'united', 'nations', 'office', 'south', 'africa', 'sir'])\n",
      " list(['greetingcsirci', 'contacting', 'believing', 'honest', 'trustworthy', 'personei', 'believe', 'betray', 'confidence', 'i', 'willing', 'repose', 'youc', 'contacted', 'even', 'though', 'weve', 'met', 'beforeemy', 'name', 'mohammed', 'tankohcthe', 'son', 'late', 'mrehassan', 'tankoh', 'chairman', 'fpresidentfceoccacaocafe', '', 'agroalimentary', 'industries', 'plcescafecaobouake', 'exowner', 'polyclinic', 'lamadonnec', 'republic', 'cote', 'divoireeyou', 'find', 'story', 'websiteahttpaffnewsebbcecoeukffhifafricafestmon', 'th', 'september', 'ca', 'group', 'called', 'rebels', 'took', 'city', 'bouake', 'overthrow', 'government', 'mrelaurent', 'gbagbo', 'president', 'cote', 'divoiree', 'on', 'th', 'day', 'morning', 'aam', 'fractions', 'group', 'rebels', 'break', 'house', 'killed', 'security', 'guard', 'passthrough', 'gate', 'entrance', 'main', 'building', 'took', 'father', 'away', 'unknown', 'destinationeafter', 'four', 'hours', 'later', 'found', 'my', 'father', 'road', 'sidec', 'totally', 'beaten', 'bleeding', 'death', 'lying', 'pool', 'bloode', 'from', 'therec', 'rushed', 'near', 'hospital', 'hours', 'later', 'sent', 'mothere', 'so', 'told'])\n",
      " list(['htmldiv', 'stylebackgroundcolordivdivdivdivdivdivdivdivdivdivdivdiv', 'classrteattnsir', 'divdiv', 'classrtenbspdivdivdivi', 'pleased', 'send', 'greeting', 'you', 'iam', 'extending', 'proposal', 'tonbsp', 'capacity', 'chairman', 'contract', 'reviewaudit', 'committeenbsp', 'scrutanizing', 'record', 'covering', 'executed', 'contract', 'awarded', 'previous', 'military', 'government', 'nigeriadivdivdivdivpmy', 'colleagues', 'i', 'uncovered', 'floating', 'amount', 'usdtwenty', 'five', 'millionfive', 'hundred', 'thousand', 'us', 'dollarswithout', 'clear', 'beneficiary', 'owing', 'deliberate', 'act', 'invoicing', 'inflating', 'contract', 'value', 'government', 'offocials', 'this', 'money', 'usdm', 'already', 'approved', 'payment', 'ministry', 'mines', 'power', 'steel', 'secure', 'contract', 'no', '', 'mmpfgnvialscon', 'job', 'completion', 'certificate', 'no', 'mmpscof', 'th', 'oct', 'as', 'top', 'civil', 'servant', 'allowed', 'operate', 'foreign', 'account', 'want', 'use', 'bank', 'account', 'transfer', 'money', 'outside', 'nigeria', 'pdivdivdivdivwe', 'accepted', 'foreign', 'partner', 'regularize', 'approvals', 'trust', 'beneficiary', 'contract', 'sum', 'as', 'soon', 'receive', 'acceptance', '', 'shall', 'inform', 'necessary', 'requirement', 'facilitate', 'transfer', 'let', 'us', 'use', 'opportunity', 'export', 'benefit', 'sum', 'resolved'])\n",
      " ...\n",
      " list(['', 'forwarded', 'mark', 'taylorhouect', '', '', 'pm', 'andrea', 'bertoneenron', '', 'am', 'to', 'mark', 'taylorhouectect', 'cc', 'remi', 'collongessaenronenron', 'ricardo', 'lisboasaenronenron', 'sami', 'arapsaenronenron', 'subject', 're', 'enrononlinemark', 'implementation', 'eol', 'project', 'brazil', 'postponed', 'because', 'regulatory', 'matters', 'the', 'market', 'rules', 'still', 'discussed', 'and', 'approved', 'aneel', 'making', 'impossible', 'us', 'implement', 'eol', 'regulatory', 'standpoint', 'recently', 'about', 'couple', 'weeks', 'ago', 'aneel', 'issued', 'resolution', '', 'approving', 'market', 'rules', 'subject', 'certain', 'amendments', 'the', 'amendments', 'implemented', 'stages', 'course', 'next', 'years', 'after', 'resolution', '', 'issued', 'regulatory', 'issues', 'partially', 'resolved', 'eol', 'team', 'decided', 'work', 'the', 'project', 'again', 'i', 'course', 'adapting', 'eta', 'gtc', 'password', 'application', 'use', 'brazil', 'i', 'probably', 'drafts', 'comments', 'within', 'next', '', 'days', 'i', 'sure', 'time', 'estimate', 'completion', 'project', 'whole', 'i', 'believe', 'remi', 'give', 'better', 'idea', 'schedulei', 'forward', 'separate', 'email', 'legal', 'opinion', 'received', 'from', 'outside', 'counsel'])\n",
      " list(['original', 'messagefrom', 'rodriquez', 'andysent', 'thursday', 'october', '', '', '', 'pmto', 'black', 'tamara', 'jae', 'odenronoudnacndrecipientscndnotesaddrcndafefbfa', 'abler', 'william', 'aggarwal', 'anubhav', 'allen', 'diana', 'arora', 'harry', 'bailey', 'debra', 'ballato', 'russell', 'ballinger', 'ted', 'baughman', 'jr', 'don', 'benchluch', 'moises', 'benjelloun', 'hicham', 'benson', 'robert', 'bentley', 'corry', 'blaine', 'jay', 'bolt', 'laurel', 'broderick', 'paul', 'j', 'broussard', 'richard', 'burnett', 'lisa', 'campbell', 'larry', 'f', 'capasso', 'joe', 'carson', 'mike', 'chen', 'alan', 'choate', 'jason', 'cline', 'kevin', 'collins', 'dustin', 'comeaux', 'keith', 'coulter', 'kayne', 'davis', 'mark', 'dana', 'day', 'smith', 'l', 'dean', 'clint', 'decook', 'todd', 'emesih', 'gerald', 'errigo', 'joe', 'forney', 'john', 'm', 'freije', 'william', 'garcia', 'miguel', 'l', 'gilbert', 'gerald', 'gilbertsmith', 'doug', 'giron', 'gustavo', 'greer', 'andrew', 'gualy', 'jaime', 'guerra', 'claudia', 'gulmeden', 'utku', 'gupta', 'gautam', 'ha', 'amie', 'hanse', 'patrick', 'hernandez', 'juan', 'imai', 'rika', 'ingram', 'david', 'jenkins', 'iv', 'daniel', 'kaniss', 'jason', 'king', 'jeff', 'kinser', 'john', 'larkworthy', 'carrie', 'laurent', 'dean', 'laverell', 'justin', 'lenartowicz', 'chris', 'lorenz', 'matt', 'lotz', 'gretchen', 'lowell', 'thomas', 'mack', 'iris', 'mahajan', 'ashish', 'makkai', 'peter', 'marquez', 'mauricio', 'maskell', 'david', 'may', 'tom', 'mcelreath', 'alexander', 'miller', 'jeffrey', 'oh', 'seungtaek', 'olinde', 'jr', 'steve', 'pace', 'andy', 'padron', 'juan', 'pan', 'steve', 'philip', 'willis', 'podurgiel', 'laura', 'poppa', 'john', 'd', 'presto', 'kevin', 'm', 'quenet', 'joe', 'rawal', 'punit', 'rogers', 'benjamin', 'rust', 'bill', 'ryan', 'david', 'saibi', 'eric', 'schiavone', 'paul', 'schneider', 'bryce', 'seely', 'michael', 'serio', 'erik', 'shoemake', 'lisa', 'simpson'])\n",
      " list(['note', 'stocks', 'heating', 'oil', 'high', 'winter', 'affecting', 'northeast', 'florida', 'markets', 'economics', 'lboriginal', 'messagefrom', 'webmasterceracom', 'mailtowebmasterceracomsent', 'friday', 'november', '', '', '', 'pmto', 'clientsceracomsubject', 'high', 'inventories', 'weak', 'jet', 'demand', 'shape', 'heating', 'oilmarket', '', 'cera', 'alert', 'title', 'atlantic', 'basin', 'heating', 'oil', 'markets', 'well', 'supplied', 'before', 'winter', 'urlshttpwwwceracomeprofileumhigh', 'inventories', 'and', 'weak', 'jet', 'demand', 'shape', 'the', 'heating', 'oil', 'marketatlantic', 'basin', 'heating', 'oil', 'markets', 'comfortably', 'supplied', 'leadup', 'the', 'winter', '', 'heating', 'season', 'accordingly', 'cera', 'expects', 'much', 'weaker', 'distillatetocrude', 'price', 'differentials', 'year', 'ago', 'primary', 'distillate', 'inventories', 'north', 'america', 'well', 'year', 'ago', 'german', 'heating', 'oil', 'stocks', 'much', '', 'million', 'barrels', 'higher', 'last', 'year', 'weakening', 'jet', 'fuel', 'demand', 'effectively', 'increases', 'availability', 'refinery', 'distillate', 'supply', 'capability', 'distillate', 'consumption', 'switchable', 'applications', 'north', 'america', 'much', 'lower', 'last', 'year', 'tight', 'natural', 'gas', 'market', 'boosted', 'distillate', 'demandendfollow', 'url', 'complete', 'alert', '', 'printed', 'pagesemail', 'category', 'alert'])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['memorandumto regulatory affairs committee power marketing working groupfrom jim steffes regulatory affairs committee chair bob reilley power marketers working group chair julie simon vice president policydate october  re october st power marketing conference call  wednesday  pm estour weekly power marketers working group conference call held wednesday october st  pm est to access call dial  ask julie simonepsa call an agenda outlined belowoctober   conference call agenda interconnection issues  anopr issued  public meeting november st  pjm interconnection meeting californiawest  ferc meeting westwide price mitigation  ferc meetings western infrastructure marketbased rate authorization rto standard market design nercgisb eisb happy halloween']\n",
      " ['no time report original messagefrom robertson audrey senttuesday october    pmtodonoho lindy lindberg lorraine lohman tk lokay michelle mcconnell mark watson kimberly ybarbo paulsubjecttime reports due tomorrowplease submitaudrey d robertsontranswestern pipeline company email address audreyrobertsonenroncom   fax']\n",
      " ['if broadband connection probably take longfor everyone else  worth wait cleansee attached file the man show boy beer standwmv']\n",
      " ...\n",
      " ['start date  hourahead hour  no ancillary schedules awarded no variances detected log messagesparsing file  oportlandwestdeskcalifornia schedulingiso final schedulestxt']\n",
      " ['dear friendin brief i mrs jessica haword wife late mr jackson haword awhite farmer murdered unknown assailants year  zimbabwemy husband great white farmer zimbabwe brutally murderedin land dispute zimbabwe agents ruling government ofpresident robert mugabe alleged support sympathy forthe oppositionmdc party led minority white farmers my husband among whiterich farmers murdered cold blood war veterans backed thegovernmentbefore death husband deposit sum usm eight million five hundred thousand united state dollars one thefinancial institution knew looming danger zimbabwe we weremarried twelve years god blessed us twins childrenpresently money still financial institution recently mydoctor told i might last next eight months due aninflammation liver this led  hours intensivecarein private clinic cotonou rep benin i tired livinglike thisi decided donate part fund individual group acharity']\n",
      " ['mr kenny colubanno yoff ruedakarsenegaltel  fax   emailkencolubanjryahoocomorzam_zamyahoocom investment assistance and partnershipdear sirmadami wish introduce you i mrkennycoluban managing director liznetinvestment andalso son chiefwilliams coluban ivorycoastabijanin west africa so father instruct meto look foreign pertner going betrustworthy god infearing able help usin investment assistance hisher company itis ok companyyou look stuitablebusiness country and got contact whilei searching net i came across mailaddress decided mail  wellpleade assistance senegaldakar business dakar so deceided moveover europe investment and father map usd  fivemillion usd investment europeanand inwest africa three branch officethegambiaabijan ivory coast senegaldakarand another things want if ableto assist usand want openan acount money investment you willsend']]\n",
      "[0 0 0 0 1]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data\n",
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        # combine list of tokens representing each email into single string\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024 # initialize output dimension of ELMo embedding\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape): # function for building ELMo embedding\n",
    "        # self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "        #                        name=\"{}_module\".format(self.name)) # download pretrained ELMo model\n",
    "        \n",
    "        self.elmo = hub.Module('https://storage.googleapis.com/tfhub-modules/google/elmo/2.tar.gz', trainable=self.trainable,\n",
    "                       name=\"{}_module\".format(self.name))\n",
    "        # extract trainable parameters, which are only a small subset of the total - this is a constraint of\n",
    "        # the tf hub module as shared by the authors - see https://tfhub.dev/google/elmo/2\n",
    "        # the trainable parameters are 4 scalar weights on the sum of the outputs of ELMo layers \n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None): # specify function for calling embedding\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape): # specify output shape\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to build overall model\n",
    "def build_model():\n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(1, activation='sigmoid')(dense) # we could use sigmoid activation as well, but we choose softmax\n",
    "                                                        # to enable us use sparse_categorical_crossentropy and \n",
    "                                                        # sparse_categorical_accuracy below\n",
    "    \n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "    # use sparse_categorical_crossentropy and sparse_categorical_accuracy do avoid having to\n",
    "    # one-hot encode the labels\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "elmo_embedding_layer_1 (Elmo (None, 1024)              4         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 262,661\n",
      "Trainable params: 262,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1400 [==========================>...] - ETA: 31s - loss: 0.3935 - acc: 0.8891"
     ]
    }
   ],
   "source": [
    "# Build and fit\n",
    "model = build_model()\n",
    "history = model.fit(train_x, \n",
    "          train_y,\n",
    "          validation_data=(test_x, test_y),\n",
    "          epochs=5,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\n",
    "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('ELMo Email Classification Training')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# Save figures\n",
    "fig.savefig('ELMoConvergence.eps', format='eps')\n",
    "fig.savefig('ELMoConvergence.pdf', format='pdf')\n",
    "fig.savefig('ELMoConvergence.png', format='png')\n",
    "fig.savefig('ELMoConvergence.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(filename='ELMoConvergence.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
