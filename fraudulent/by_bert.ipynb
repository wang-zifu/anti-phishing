{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "!pip install keras==2.2.4 # critical dependency\n",
    "#!pip install -q bert-tensorflow\n",
    "!pip install bert-tensorflow==1.0.1\n",
    "!pip install tensorflow==2.3.0 X\n",
    "!pip install tensorflow==1.15.0\n",
    "!pip install tensorflow_datasets\n",
    "!pip install tensorflow_hub\n",
    "!pip install pyopenssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.2.4-tf\n",
      "2.2.4\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Some other key imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "filepath = \"../data/enron/emails.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe called emails\n",
    "emails = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# take a closer look at the first email\n",
    "print(emails.loc[0][\"message\"])\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#messages = emails[\"message\"].apply(email.message_from_string)\n",
    "#bodies_df = messages.apply(lambda x: x.get_payload()).sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../data/fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list(['strictly', 'confidential', '', 'urgenttel', '', '', 'fax', '', '', 'tel', '', '', 'alternative', 'email', 'addresserickericklatinmailcomdear', 'siri', 'mrtambo', 'native', 'cape', 'town', 'south', 'africa', 'i', 'executive', 'accountant', 'south', 'africa', 'department', 'mining', '', 'natural', 'resources', 'first', 'foremost', 'i', 'apologized', 'using', 'medium', 'reach', 'transactionbusiness', 'magnitude', 'due', 'confidentiality', 'prompt', 'access', 'reposed', 'medium', 'be', 'informed', 'member', 'south', 'africa', 'export', 'promotion', 'council', 'sepc', 'government', 'delegation', 'country', 'trade', 'exhibition', 'gave', 'enviable', 'credentialsparticulars', 'me', 'i', 'decided', 'seek', 'confidential', 'cooperation', 'execution', 'deal', 'described', 'hereunder', 'benefit', 'parties', 'hope', 'keep', 'top', 'secret', 'nature', 'transactionwithin', 'department', 'mining', '', 'natural', 'resources', 'i', 'work'])\n",
      " list([])\n",
      " list(['confidential', 'proposal', 'code', 'no', 'amgood', 'dayi', 'mr', 'ming', 'yang', 'director', 'operations', 'hang', 'seng', 'bank', 'ltd', 'saiwan', 'ho', 'branch', 'hong', 'kong', 'my', 'purpose', 'contacting', 'dontleave', 'hong', 'kongi', 'obscured', 'business', 'suggestion', 'youi', 'hereby', 'seeking', 'yourservice', 'helping', 'recieve', 'large', 'amount', 'money', 'giving', 'aclear', 'research', 'feasibility', 'studies', 'areas', 'i', 'could', 'invest', 'on', 'yourservices', 'paid', 'for', 'partner', 'yourrecommendation', 'acceptedas', 'bank', 'employee', 'i', 'operate', 'personal', 'investment', 'till', 'i', 'amretired', 'anticorruption', 'bill', 'passed', 'hong', 'kong', 'riskyfor', 'fixed', 'income', 'earner', 'huge', 'amount', 'money', 'hong', 'kong', 'orany', 'foreign', 'country', 'it', 'advisable', 'invest', 'foreign', 'landsecretly', 'patiently', 'wait', 'retirementfor', 'security', 'purpose', 'due', 'telecom', 'interception', 'hong', 'kong', 'i', 'shallnot', 'accept', 'acknowledge', 'phone', 'call', 'only', 'fax', 'messagesemails', 'wouldbe', 'treated', 'relation', 'proposal', 'without', 'code', 'codeno', 'am', 'should', 'interested', 'i', 'would', 'prefer', 'toreach', 'soon', 'finally', 'i', 'shall', 'provide', 'detailsof', 'operationkind'])\n",
      " ...\n",
      " list(['', 'forwarded', 'steve', 'c', 'hallpdxect', '', '', 'pm', 'chris_a_andersoncalpxcom', '', '', 'pmto', 'stevechallenroncomcc', 'subject', 'see', 'attached', 'file', 'enroncollateraldoc', '', 'enroncollateraldoc'])\n",
      " list(['please', 'include', 'following', 'andrea', 'nicks', '', 'aquila', '', 'scott', 'garrison', '', 'axia', 'pat', 'bergin', '', 'axia', 'brian', 'rickers', '', 'sempra', 'mark', 'chambers', '', 'coral', 'ann', 'riopelle', '', 'coral', 'ragan', 'bond', '', 'bridgeline', 'chris', 'cokinos', '', 'cokinos'])\n",
      " list(['steve', 'was', 'lorraine', 'able', 'get', 'answer', 'left', 'i', 'know', 'calls', 'nevada', 'power', 'let', 'know', 'need', 'anything', 'absence', 'kim', 'original', 'messagefrom', 'harris', 'steven', 'sentfriday', 'november', '', '', '', 'amtolindberg', 'lorraineccwatson', 'kimberlysubjectre', 'southwest', 'gascan', 'please', 'find', 'persons', 'charge', 'fuel', 'procurement', 'nevada', 'power', 'currently', 'is', 'name', 'phone', 'number', 'title', 'would', 'help', 'either', 'someone', 'director', 'vp', 'level', 'thanks', '', 'original', 'messagefrom', 'lindberg', 'lorraine', 'sentfriday', 'november', '', '', '', 'amtoharris', 'stevensubjectre', 'southwest', 'gasthe', 'last', 'time', 'i', 'spoke', 'anyone', 'np', '', 'yrs', 'ago', 'john', 'olenick', 'ft', 'impending', 'dereg', 'to', 'knowledge', 'one', 'las', 'vegas', 'cogen', 'approached', 'directly', 'original', 'messagefrom', 'harris', 'steven', 'sentthursday', 'november', '', '', '', 'pmtolindberg', 'lorrainesubjectre', 'southwest', 'gaswho', 'nevada', 'power', 'talking', 'capacity', 'las', 'vegas', 'cogen', 'original', 'messagefrom', 'lindberg', 'lorraine', 'sentwednesday', 'october', '', '', '', 'pmtoharris', 'stevenccwatson', 'kimberlysubjectsouthwest', 'gassteve', '', 'in', 'response', 'previous', 'questions', 'regarding', 'customers', 'behind', 'swg', 'swgs', 'largest', 'customers'])]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['kaye please verify phone number calendar sara shackletonenron north america corp smith street eb ahouston texas  phone faxsarashackletonenroncom forwarded sara shackletonhouect   am stewart rosmanenronenronxgate  pm  to sara shackletonhouectect cc  subject conference call requestsara jeff fuller prm requesting conference call next wednesday mayth refreash memory represents nw puds  wants to discuss isda process prepared move forward  i believe opion letter then if possble schedule time works him his number  thanksstewart']\n",
      " ['tim i think robs new email addressbestjeff']\n",
      " [' forwarded darron c gironhouect   am  from larry joe hunter   amto kam keiserhouectect phillip m lovehouectect david baumbachhouectect errol mclaughlincorpenronenron darron c gironhouectectcc ellen wallumrodnaenronenron richard demingnaenronenron subject coenergy trading companyplease forward ellen wallumrod mtm valuationminibook coenergy trading company deals dec   if export excel forward email would appreciatedthanksjoe']\n",
      " ...\n",
      " ['my name daniel williams i artisti live netherlandswith twokids four cats one dog love life it definitely fullhouse i artwork since i small child that gives about years experience i majored art high school took collegeart courses most work done either pencil airbrush mixed withcolor pencils i recently added designing creating artwork thecomputeri selling art last  years workfeatured trading cards prints magazinesi sold galleries andto private collectors around worldi always facing seriousdifficulties comes selling art works americansthey alwaysoffering pay us postal money orderwhich difficult cashhere netherlandi looking representative states working andwill willing pay  every transactionwhich wouldnt affect urpresent state worksomeone would help recieve payments mycustomers statesthese payments money order']\n",
      " ['hey doveryou one figured hell i saying so manypeople sent back dumbass responses fat i thought iwas creative obviously not i rio new years andit sick time i digital pictures i send next timei download floppy disk the people rio cool showing asmuch skin possible custom i trying finish myapplications i think i submitted end ofjanuary i hear ob actually go back work i hope handleit i visited christmas partying like senior year ofcollegei still forgotten wedding gift getting i inthe far east something guys always rememberhow many slaves doyou think need real cheapchobs original message from benjamin rogers smtpbrogersectenroncom sent sunday january    pm to choby c subject re new address hey there do know big']\n",
      " ['priscilla said mid american called said pay us receive invoice have pathed yet let know thxoriginal messagefrom germany chris sent friday april    amto dinari sabra lsubject re enbridge consumers gas park  loani think needs pathed unify heres problem i created sales deal ticket kim i know supply needed come imbalance i needed create one sided exchange ticket i idea ontario desk handled past they probably consistent any would path this just take best shot it i think going quite things like this im trying figure put sales deal ticket jan  montanna power westoriginal messagefrom dinari sabra l sent friday april    amto germany chrissubject re enbridge consumers gas park  loanchrissy something i need this ive']]\n",
      "[0 0 0 0 0]\n",
      "(1400,)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data in unison with labels/header\n",
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module = hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"mean\",\n",
    "        # bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        bert_path=\"https://storage.googleapis.com/tfhub-modules/google/bert_uncased_L-12_H-768_A-12/1.tar.gz\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Function to build overall model\n",
    "def build_model(max_seq_length):\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    # just extract BERT features, don't fine-tune\n",
    "    bert_output = BertLayer(n_fine_tune_layers=0)(bert_inputs)\n",
    "    # train dense classification layer on top of extracted features\n",
    "    dense = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to initialize variables correctly\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Converting examples to features: 100%|██████████| 1400/1400 [00:02<00:00, 573.51it/s]\n",
      "Converting examples to features: 100%|██████████| 600/600 [00:01<00:00, 551.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/ant-phishing/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 197,121\n",
      "Non-trainable params: 110,104,890\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "1400/1400 [==============================] - 362s 259ms/sample - loss: 0.1861 - acc: 0.9329 - val_loss: 0.0762 - val_acc: 0.9783\n",
      "Epoch 2/5\n",
      "1400/1400 [==============================] - 366s 262ms/sample - loss: 0.0367 - acc: 0.9936 - val_loss: 0.0514 - val_acc: 0.9833\n",
      "Epoch 3/5\n",
      "1400/1400 [==============================] - 379s 271ms/sample - loss: 0.0193 - acc: 0.9979 - val_loss: 0.0422 - val_acc: 0.9850\n",
      "Epoch 4/5\n",
      "1400/1400 [==============================] - 380s 271ms/sample - loss: 0.0117 - acc: 0.9979 - val_loss: 0.0435 - val_acc: 0.9850\n",
      "Epoch 5/5\n",
      "1400/1400 [==============================] - 375s 268ms/sample - loss: 0.0087 - acc: 0.9993 - val_loss: 0.0398 - val_acc: 0.9867\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# tf hub bert model path\n",
    "# bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" \n",
    "bert_path = \"https://storage.googleapis.com/tfhub-modules/google/bert_uncased_L-12_H-768_A-12/1.tar.gz\" \n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_x, train_y)\n",
    "test_examples = convert_text_to_examples(test_x, test_y)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids,train_input_masks,train_segment_ids,train_labels) = \\\n",
    "convert_examples_to_features(tokenizer, train_examples, max_seq_length=maxtokens)\n",
    "(test_input_ids,test_input_masks,test_segment_ids,test_labels) = \\\n",
    "convert_examples_to_features(tokenizer, test_examples, max_seq_length=maxtokens)\n",
    "\n",
    "# Build model\n",
    "model = build_model(maxtokens)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "# Train model\n",
    "history = model.fit([train_input_ids, train_input_masks, train_segment_ids],train_labels,\n",
    "                    validation_data=([test_input_ids, test_input_masks, test_segment_ids],test_labels),\n",
    "                    epochs=5,batch_size=32)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\n",
    "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('BERT Email Classification Training')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('BERTConvergence.eps', format='eps')\n",
    "fig.savefig('BERTConvergence.pdf', format='pdf')\n",
    "fig.savefig('BERTConvergence.png', format='png')\n",
    "fig.savefig('BERTConvergence.svg', format='svg')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(filename='BERTConvergence.svg')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
